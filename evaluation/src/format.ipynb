{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fb46e81-13e8-41fc-a4aa-cd34bc8ec552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found based on 'query' and 'groundtruth'.\n"
     ]
    }
   ],
   "source": [
    "# check duplicates\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the TSV file\n",
    "groundtruth_df = pd.read_csv('../query_groundtruth.tsv', sep='\\t')\n",
    "\n",
    "# Check for duplicates based on both \"query\" and \"groundtruth\" columns\n",
    "duplicates = groundtruth_df[groundtruth_df.duplicated(subset=['query', 'groundtruth'], keep=False)]\n",
    "\n",
    "# Print or save the duplicate entries\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicate rows based on 'query' and 'groundtruth':\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicates found based on 'query' and 'groundtruth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c86931e4-788b-40e9-820f-787424ece75b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved in siblings.json\n",
      "                                 original  \\\n",
      "0                  AREA_sw_0_7_s_0_7_cc_0   \n",
      "1                  AREA_sw_0_7_s_0_7_cc_0   \n",
      "2                  AREA_sw_0_7_s_0_7_cc_0   \n",
      "3                  AREA_sw_0_7_s_0_7_cc_0   \n",
      "4                  AREA_sw_0_7_s_0_7_cc_0   \n",
      "...                                   ...   \n",
      "4022  viridis-heatmap_p_0_sw_1_2_s_1_0_oc   \n",
      "4023  viridis-heatmap_p_0_sw_1_2_s_1_0_oc   \n",
      "4024  viridis-heatmap_p_0_sw_1_2_s_1_0_oc   \n",
      "4025  viridis-heatmap_p_0_sw_1_2_s_1_0_oc   \n",
      "4026  viridis-heatmap_p_0_sw_1_2_s_1_0_oc   \n",
      "\n",
      "                                          query  \\\n",
      "0                  AREA_sw_0_7_s_0_7_cc_0_query   \n",
      "1                  AREA_sw_0_7_s_0_7_cc_0_query   \n",
      "2                  AREA_sw_0_7_s_0_7_cc_0_query   \n",
      "3                  AREA_sw_0_7_s_0_7_cc_0_query   \n",
      "4                  AREA_sw_0_7_s_0_7_cc_0_query   \n",
      "...                                         ...   \n",
      "4022  viridis-heatmap_p_0_sw_1_2_s_1_0_oc_query   \n",
      "4023  viridis-heatmap_p_0_sw_1_2_s_1_0_oc_query   \n",
      "4024  viridis-heatmap_p_0_sw_1_2_s_1_0_oc_query   \n",
      "4025  viridis-heatmap_p_0_sw_1_2_s_1_0_oc_query   \n",
      "4026  viridis-heatmap_p_0_sw_1_2_s_1_0_oc_query   \n",
      "\n",
      "                              groundtruth  \n",
      "0                  AREA_sw_1_2_s_1_2_cc_0  \n",
      "1                  AREA_sw_1_0_s_1_0_cc_0  \n",
      "2                  AREA_sw_1_2_s_1_0_cc_0  \n",
      "3                  AREA_sw_0_7_s_1_0_cc_0  \n",
      "4                  AREA_sw_1_0_s_1_2_cc_0  \n",
      "...                                   ...  \n",
      "4022  viridis-heatmap_p_0_sw_0_7_s_1_0_oc  \n",
      "4023  viridis-heatmap_p_0_sw_1_0_s_1_2_oc  \n",
      "4024  viridis-heatmap_p_0_sw_1_2_s_0_7_oc  \n",
      "4025  viridis-heatmap_p_0_sw_0_7_s_1_2_oc  \n",
      "4026  viridis-heatmap_p_0_sw_1_0_s_1_0_oc  \n",
      "\n",
      "[4027 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# connect two tables\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the TSV files\n",
    "original_df = pd.read_csv('../original.tsv', sep='\\t')\n",
    "groundtruth_df = pd.read_csv('../query_groundtruth.tsv', sep='\\t')\n",
    "\n",
    "# Remove rows with any NaN values (empty rows) in both DataFrames\n",
    "original_df = original_df.dropna()\n",
    "groundtruth_df = groundtruth_df.dropna()\n",
    "\n",
    "# Merge the dataframes on the \"query\" column\n",
    "merged_df = pd.merge(original_df, groundtruth_df, on='query', how='inner')\n",
    "\n",
    "# Reorder columns to switch \"query\" and \"original\"\n",
    "column_order = ['original', 'query', 'groundtruth']\n",
    "merged_df = merged_df[column_order]\n",
    "\n",
    "# Create a dictionary with \"original\" as keys and lists of \"groundtruth\" as values\n",
    "siblings_dict = {}\n",
    "for _, row in merged_df.iterrows():\n",
    "    original = row['original']\n",
    "    groundtruth = row['groundtruth']\n",
    "    \n",
    "    if original not in siblings_dict:\n",
    "        siblings_dict[original] = []\n",
    "    siblings_dict[original].append(groundtruth)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open('siblings.json', 'w') as json_file:\n",
    "    json.dump(siblings_dict, json_file, indent=4)\n",
    "\n",
    "print(\"Dictionary saved in siblings.json\")\n",
    "\n",
    "# Save to a new TSV file or print the result\n",
    "merged_df.to_csv('merged.tsv', sep='\\t', index=False)\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b35317-75c0-4bf3-be98-6e8c77952952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display_html, HTML\n",
    "\n",
    "def display_images_with_text_below(df):\n",
    "    html = \"\"\"<table border='1' style='border-collapse: collapse; text-align: center;'>\n",
    "              <tr><th>Original</th><th>Query</th><th>Groundtruth</th></tr>\"\"\"\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        html += \"<tr>\"\n",
    "\n",
    "        # Original image and text below\n",
    "        html += f\"\"\"\n",
    "            <td>\n",
    "                <img src=\"{row['image_original']}\" style=\"width:300px;\"><br>\n",
    "                <div style=\"padding: 4px; word-break: break-word;\">{row['original']}</div>\n",
    "            </td>\n",
    "        \"\"\"\n",
    "\n",
    "        # Query image and text below\n",
    "        html += f\"\"\"\n",
    "            <td>\n",
    "                <img src=\"{row['image']}\" style=\"width:300px;\"><br>\n",
    "                <div style=\"padding: 4px; word-break: break-word;\">{row['query']}</div>\n",
    "            </td>\n",
    "        \"\"\"\n",
    "\n",
    "        # Groundtruth image and text below\n",
    "        html += f\"\"\"\n",
    "            <td>\n",
    "                <img src=\"{row['image_groundtruth']}\" style=\"width:300px;\"><br>\n",
    "                <div style=\"padding: 4px; word-break: break-word;\">{row['groundtruth']}</div>\n",
    "            </td>\n",
    "        \"\"\"\n",
    "\n",
    "        html += \"</tr>\"\n",
    "\n",
    "    html += \"</table>\"\n",
    "    display_html(HTML(html))\n",
    "\n",
    "# Load the TSV\n",
    "df = pd.read_csv('merged.tsv', sep='\\t')\n",
    "\n",
    "# Construct full image paths\n",
    "df['image'] = '../../data/test_suite/imgs/' + df['query'] + '.png'\n",
    "df['image_original'] = '../../data/unified/imgs/' + df['original'] + '.png'\n",
    "df['image_groundtruth'] = '../../data/unified/imgs/' + df['groundtruth'] + '.png'\n",
    "\n",
    "# Display\n",
    "display_images_with_text_below(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c5d2c-554d-4f32-9619-7acc62d7aef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
