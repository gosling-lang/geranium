{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6388b7f9-8208-4284-8070-5119d7c20723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add chromoscope\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# Example array A\n",
    "A = [\"BOCA-UK-f83fc777-5416-c3e9-e040-11ac0d482c8e_query1\", \"BOCA-UK-f83fc777-5416-c3e9-e040-11ac0d482c8e_query2\", \n",
    "     \"EX_SPEC_CANCER_VARIANT_PROTOTYPE_sw_1_0_s_1_2_query1\", \"breast_cancer_circular_s_2_0_oc_query\"]\n",
    "\n",
    "# Folder B (update with your actual path)\n",
    "folder_B = \"../data/chromoscope/imgs\"\n",
    "\n",
    "# Get all filenames in B, stripping extensions\n",
    "files_B = [os.path.splitext(f)[0] for f in os.listdir(folder_B) if os.path.isfile(os.path.join(folder_B, f))]\n",
    "\n",
    "# Create all combinations\n",
    "combinations = list(itertools.product(A, files_B))\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame(combinations, columns=[\"query\", \"GT_extended\"])\n",
    "\n",
    "# Save to TSV\n",
    "df.to_csv(\"query_GT_p2_chromoscope.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "852d80b5-c697-422e-a3db-30d79d9bf48d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1' style='border-collapse: collapse; text-align: center;'>\n",
       "              <tr><th>#</th><th>Query</th><th>Related Match</th></tr><tr><td>2</td>\n",
       "            <td>\n",
       "                <img src=\"../data/test_suite/imgs/EX_SPEC_MATRIX_sw_0_7_s_0_7_oc_viridis_query1.png\" style=\"width:250px;\"><br>\n",
       "                <div style=\"padding: 4px; word-break: break-word;\">EX_SPEC_MATRIX_sw_0_7_s_0_7_oc_viridis_query1</div>\n",
       "            </td>\n",
       "        \n",
       "            <td>\n",
       "                <img src=\"../data/unified/imgs/EX_SPEC_MATRIX_sw_0_7_s_0_7_oc_viridis.png\" style=\"width:250px;\"><br>\n",
       "                <div style=\"padding: 4px; word-break: break-word;\">EX_SPEC_MATRIX_sw_0_7_s_0_7_oc_viridis</div>\n",
       "            </td>\n",
       "        </tr><tr><td>3</td>\n",
       "            <td>\n",
       "                <img src=\"../data/test_suite/imgs/EX_SPEC_MATRIX_sw_0_7_s_0_7_oc_viridis_query2.png\" style=\"width:250px;\"><br>\n",
       "                <div style=\"padding: 4px; word-break: break-word;\">EX_SPEC_MATRIX_sw_0_7_s_0_7_oc_viridis_query2</div>\n",
       "            </td>\n",
       "        \n",
       "            <td>\n",
       "                <img src=\"../data/unified/imgs/EX_SPEC_MATRIX_sw_0_7_s_0_7_oc_viridis.png\" style=\"width:250px;\"><br>\n",
       "                <div style=\"padding: 4px; word-break: break-word;\">EX_SPEC_MATRIX_sw_0_7_s_0_7_oc_viridis</div>\n",
       "            </td>\n",
       "        </tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import display_html, HTML\n",
    "\n",
    "# Define folders\n",
    "query_folder = '../data/test_suite/imgs'\n",
    "unified_folder = '../data/unified/imgs'\n",
    "\n",
    "# Load main DataFrame\n",
    "df0 = pd.read_csv('GT_absolute.tsv', sep='\\t')\n",
    "\n",
    "# Load A.tsv which contains the list of allowed queries\n",
    "query_df = pd.read_csv('unmatched_queries_rest5.tsv', sep='\\t')  # assuming A is also tab-separated and has a column 'query'\n",
    "\n",
    "# Load main DataFrame\n",
    "df0['query'] = df0['query'].str.strip()\n",
    "query_df['query'] = query_df['query'].str.strip()\n",
    "\n",
    "# Filter rows in df where 'query' exists in query_df\n",
    "df = df0[df0['query'].isin(query_df['query'])]\n",
    "\n",
    "# List all images in the unified folder\n",
    "all_unified_images = os.listdir(unified_folder)\n",
    "\n",
    "def find_related_files(groundtruth_name, all_files):\n",
    "    # Ensure file ends with .png\n",
    "    if not groundtruth_name.endswith('.png'):\n",
    "        groundtruth_name += '.png'\n",
    "\n",
    "    # Determine suffix type: either _cc or _oc\n",
    "    cc_oc_match = re.search(r'(_viridis(?:_recolor)?)\\.png$', groundtruth_name)\n",
    "    if not cc_oc_match:\n",
    "        return []\n",
    "\n",
    "    suffix = cc_oc_match.group()  # like _cc_0.png or _oc.png\n",
    "\n",
    "    # Get mainname before the last _sw\n",
    "    sw_split = groundtruth_name.rsplit('_sw', 1)\n",
    "    if len(sw_split) < 2:\n",
    "        return []\n",
    "    mainname = sw_split[0]  # like AREA\n",
    "\n",
    "    # Find all files with same mainname prefix and suffix (_cc or _oc)\n",
    "    related = [\n",
    "        fname for fname in all_files\n",
    "        if fname.startswith(mainname) and fname.endswith(suffix) and 'HFF' not in fname\n",
    "    ]\n",
    "    return related\n",
    "\n",
    "\n",
    "# Collect data\n",
    "rows = []\n",
    "index = 2\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    query_name = row['query']\n",
    "    groundtruth_name = row['groundtruth'] + '.png'\n",
    "    \n",
    "    related_files = find_related_files(groundtruth_name, all_unified_images)\n",
    "    \n",
    "    for related_file in related_files:\n",
    "        rows.append({\n",
    "            'index': index,\n",
    "            'query': query_name,\n",
    "            'query_image': os.path.join(query_folder, query_name + '.png'),\n",
    "            'groundtruth': row['groundtruth'],\n",
    "            'groundtruth_image': os.path.join(unified_folder, groundtruth_name),\n",
    "            'groundtruth_extended': os.path.splitext(related_file)[0],\n",
    "            'related_image': os.path.join(unified_folder, related_file)\n",
    "        })\n",
    "        index += 1\n",
    "\n",
    "# Create DataFrame\n",
    "expanded_df = pd.DataFrame(rows)\n",
    "\n",
    "# Save the DataFrame to a TSV file with two columns: query and related\n",
    "# expanded_df[['query', 'groundtruth_extended']].to_csv('./query_GT_p11.tsv', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "# Display function\n",
    "def display_query_gt_related_table(df):\n",
    "    html = \"\"\"<table border='1' style='border-collapse: collapse; text-align: center;'>\n",
    "              <tr><th>#</th>\"\"\"\n",
    "    # html += \"\"\"<th>Groundtruth</th>\"\"\"\n",
    "    html += \"\"\"<th>Query</th><th>Related Match</th></tr>\"\"\"\n",
    "\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        html += \"<tr>\"\n",
    "        \n",
    "        html += f\"<td>{row['index']}</td>\"\n",
    "\n",
    "        # html += f\"\"\"\n",
    "        #     <td>\n",
    "        #         <img src=\"{row['groundtruth_image']}\" style=\"width:250px;\"><br>\n",
    "        #         <div style=\"padding: 4px; word-break: break-word;\">{row['groundtruth']}</div>\n",
    "        #     </td>\n",
    "        # \"\"\"\n",
    "        \n",
    "        html += f\"\"\"\n",
    "            <td>\n",
    "                <img src=\"{row['query_image']}\" style=\"width:250px;\"><br>\n",
    "                <div style=\"padding: 4px; word-break: break-word;\">{row['query']}</div>\n",
    "            </td>\n",
    "        \"\"\"\n",
    "            \n",
    "        html += f\"\"\"\n",
    "            <td>\n",
    "                <img src=\"{row['related_image']}\" style=\"width:250px;\"><br>\n",
    "                <div style=\"padding: 4px; word-break: break-word;\">{row['groundtruth_extended']}</div>\n",
    "            </td>\n",
    "        \"\"\"\n",
    "\n",
    "        html += \"</tr>\"\n",
    "\n",
    "    html += \"</table>\"\n",
    "    display_html(HTML(html))\n",
    "\n",
    "# Display the result\n",
    "display_query_gt_related_table(expanded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cddee144-033a-4f27-95af-5950879cd0a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two TSV files\n",
    "df_a = pd.read_csv('unmatched_queries_rest7.tsv', sep='\\t')\n",
    "df_b = pd.read_csv('query_GT_p10.tsv', sep='\\t')\n",
    "\n",
    "# Clean up any extra spaces or invisible characters\n",
    "df_a['query'] = df_a['query'].str.strip()\n",
    "df_b['query'] = df_b['query'].str.strip()\n",
    "\n",
    "# Filter: keep only rows in A where query is NOT in B\n",
    "filtered_a = df_a[~df_a['query'].isin(df_b['query'])]\n",
    "\n",
    "# Save or use the result\n",
    "filtered_a.to_csv('unmatched_queries_rest8.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6218a2bd-cf84-427e-b9f5-b28ea31f13f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>groundtruth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AREA_sw_0_7_s_0_7_cc_0_query</td>\n",
       "      <td>AREA_sw_0_7_s_0_7_cc_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AREA_sw_0_7_s_1_0_cc_1_query</td>\n",
       "      <td>AREA_sw_0_7_s_1_0_cc_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AREA_sw_0_7_s_1_2_cc_3_query</td>\n",
       "      <td>AREA_sw_0_7_s_1_2_cc_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AREA_sw_1_0_s_0_7_oc_query</td>\n",
       "      <td>AREA_sw_1_0_s_0_7_oc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AREA_sw_1_2_s_0_7_cc_2_query</td>\n",
       "      <td>AREA_sw_1_2_s_0_7_cc_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>stratified-line_p_0_sw_1_2_s_1_2_oc_query</td>\n",
       "      <td>stratified-line_p_0_sw_1_2_s_1_2_oc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>stratified-point_p_0_sw_0_7_s_0_7_cc_0_query</td>\n",
       "      <td>stratified-point_p_0_sw_0_7_s_0_7_cc_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>stratified-point_p_0_sw_1_2_s_1_2_oc_query</td>\n",
       "      <td>stratified-point_p_0_sw_1_2_s_1_2_oc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>viridis-heatmap_p_0_sw_0_7_s_0_7_cc_0_query</td>\n",
       "      <td>viridis-heatmap_p_0_sw_0_7_s_0_7_cc_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>viridis-heatmap_p_0_sw_1_2_s_1_0_oc_query</td>\n",
       "      <td>viridis-heatmap_p_0_sw_1_2_s_1_0_oc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            query  \\\n",
       "0                    AREA_sw_0_7_s_0_7_cc_0_query   \n",
       "1                    AREA_sw_0_7_s_1_0_cc_1_query   \n",
       "2                    AREA_sw_0_7_s_1_2_cc_3_query   \n",
       "3                      AREA_sw_1_0_s_0_7_oc_query   \n",
       "4                    AREA_sw_1_2_s_0_7_cc_2_query   \n",
       "..                                            ...   \n",
       "199     stratified-line_p_0_sw_1_2_s_1_2_oc_query   \n",
       "200  stratified-point_p_0_sw_0_7_s_0_7_cc_0_query   \n",
       "201    stratified-point_p_0_sw_1_2_s_1_2_oc_query   \n",
       "202   viridis-heatmap_p_0_sw_0_7_s_0_7_cc_0_query   \n",
       "203     viridis-heatmap_p_0_sw_1_2_s_1_0_oc_query   \n",
       "\n",
       "                                groundtruth  \n",
       "0                    AREA_sw_0_7_s_0_7_cc_0  \n",
       "1                    AREA_sw_0_7_s_1_0_cc_1  \n",
       "2                    AREA_sw_0_7_s_1_2_cc_3  \n",
       "3                      AREA_sw_1_0_s_0_7_oc  \n",
       "4                    AREA_sw_1_2_s_0_7_cc_2  \n",
       "..                                      ...  \n",
       "199     stratified-line_p_0_sw_1_2_s_1_2_oc  \n",
       "200  stratified-point_p_0_sw_0_7_s_0_7_cc_0  \n",
       "201    stratified-point_p_0_sw_1_2_s_1_2_oc  \n",
       "202   viridis-heatmap_p_0_sw_0_7_s_0_7_cc_0  \n",
       "203     viridis-heatmap_p_0_sw_1_2_s_1_0_oc  \n",
       "\n",
       "[204 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c683a81-2c51-4d1e-8d2a-5cedaedbf781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File lengths (after header skip and cleaning):\n",
      "./components/query_GT_p9.tsv: 12 rows\n",
      "./components/query_GT_p8.tsv: 18 rows\n",
      "./components/query_GT_p2_chromoscope.tsv: 1924 rows\n",
      "./components/query_GT_p10.tsv: 4 rows\n",
      "./components/query_GT_p11.tsv: 2 rows\n",
      "./components/query_GT_p6.tsv: 6 rows\n",
      "./components/query_GT_p7.tsv: 14 rows\n",
      "./components/query_GT_p5.tsv: 7 rows\n",
      "./components/query_GT_p4.tsv: 133 rows\n",
      "./components/query_GT_p1.tsv: 1606 rows\n",
      "./components/query_GT_p3.tsv: 117 rows\n",
      "\n",
      "Total concatenated rows: 3843\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Path to your TSV files (adjust the pattern as needed)\n",
    "tsv_files = glob.glob(\"./components/*.tsv\")\n",
    "\n",
    "all_dfs = []\n",
    "total_rows = 0\n",
    "\n",
    "print(\"File lengths (after header skip and cleaning):\")\n",
    "for file in tsv_files:\n",
    "    # Read file skipping header row\n",
    "    df = pd.read_csv(file, sep='\\t', skiprows=1, header=None, engine='python', encoding='utf-8', on_bad_lines='skip')\n",
    "    df = df.dropna(how='all')  # Remove completely empty rows\n",
    "    print(f\"{file}: {len(df)} rows\")\n",
    "    all_dfs.append(df)\n",
    "    total_rows += len(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Keep and rename only the first two columns\n",
    "combined_df = combined_df.iloc[:, :2]\n",
    "combined_df.columns = ['query', 'gt_extended']\n",
    "\n",
    "# Drop rows with missing query or gt_extended\n",
    "combined_df = combined_df.dropna(subset=['query', 'gt_extended'])\n",
    "\n",
    "# Sort alphabetically by 'query'\n",
    "combined_df = combined_df.sort_values(by='query').reset_index(drop=True)\n",
    "\n",
    "# Final length\n",
    "print(f\"\\nTotal concatenated rows: {len(combined_df)}\")\n",
    "\n",
    "# Save to TSV\n",
    "combined_df.to_csv(\"combined_output.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df1612-e8ba-48e5-9155-066032b64c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "EX_SPEC_RESPONSIVE_COMPARATIVE_MATRICES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
