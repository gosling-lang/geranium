{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates text descriptions based on altgosling output, specs, image, with an LLM.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import base64\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need an API key for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.environ['API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repo = \"../data/unified\"\n",
    "lhs_path = \"./cfg_rules_lhs.csv\"\n",
    "\n",
    "with open(lhs_path, \"r\") as f:\n",
    "    lhs = f.read()\n",
    "\n",
    "specs_dir = os.path.join(data_repo, \"specs\")\n",
    "imgs_dir = os.path.join(data_repo, \"imgs\")\n",
    "alt_dir = os.path.join(data_repo, \"alt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(name):\n",
    "    with open(os.path.join(specs_dir, f\"{name}.json\"), 'r') as f:\n",
    "        spec = f.read()\n",
    "    \n",
    "    with open(os.path.join(imgs_dir, f\"{name}.png\"), \"rb\") as f:\n",
    "        img = f.read()\n",
    "    img_base64 = base64.b64encode(img).decode(\"utf-8\")\n",
    "\n",
    "    with open(os.path.join(alt_dir, \"altgosling\", f\"{name}.txt\"), \"r\") as f:\n",
    "        alt = f.read()\n",
    "\n",
    "    with open(os.path.join(alt_dir, \"processedspec\", f\"{name}.json\"), \"r\") as f:\n",
    "        processed_spec = f.read()\n",
    "\n",
    "    return {\"name\": name, \"spec\": spec, \"img\": img_base64, \"alt\": alt, \"processed_spec\": processed_spec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load few shot examples\n",
    "with open(\"few_shot_learning_examples.json\", \"r\") as f:\n",
    "    fewshot = json.load(f)\n",
    "\n",
    "fewshots = []\n",
    "for f in fewshot:\n",
    "    obj = get_files(f)\n",
    "    obj[\"description\"] = fewshot[f]\n",
    "    fewshots.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "I want to generate a text description of a visualization. \n",
    "The visualization is a json specification. \n",
    "I already have created an automatic alt text.\n",
    "I also have classified the attributes of the specification.\n",
    "I will use the text description in a multimodal search engine. \n",
    "The description should be as informative as possible.\n",
    "\"\"\"\n",
    "model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## few shot result in too many tokens\n",
    "\n",
    "# prompt = f\"\"\"\n",
    "# I want to generate a text description of a visualization. \n",
    "# The visualization is a json specification. \n",
    "# I already have created an automatic alt text.\n",
    "# I also have classified the attributes of the specification.\n",
    "# I will use the text description in a multimodal search engine. \n",
    "# The description should be as informative as possible.\n",
    "\n",
    "# Here are some examples of visualizations, their specs, images, alt texts, processed specs, and the description, which is the desired output.\n",
    "# {fewshots}\n",
    "# \"\"\"\n",
    "# model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_prompt(prompt, model, files):\n",
    "    client = OpenAI(\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"text\", \"text\": f\"spec: {files['spec']}\"},\n",
    "                    {\"type\": \"text\", \"text\": f\"processed spec: {files['processed_spec']}\"},\n",
    "                    {\"type\": \"text\", \"text\": f\"altgosling alt: {files['alt']}\"},\n",
    "                    {\"type\": \"text\", \"text\": f\"attribute classification: {lhs}\"},\n",
    "                    {\"type\": \"image_url\",\n",
    "                     \"image_url\": {\n",
    "                         \"url\": f\"data:image/png;base64,{files['img']}\",\n",
    "                     }}\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The visualization is a circular bar chart depicting genomic data based on the hg38 assembly. It features a static layout with a center radius of 0.3 and circular alignment. The chart comprises pink bars representing quantitative expression values plotted against genomic positions on the x-axis. The chart has no interactions enabled, emphasizing purely visual data representation. The spacing is set to 1, and all tracks share the same alignment, optimizing the view for easy comparison of data peaks across different chromosomal positions. The outer radius measures approximately 171.5 with an inner radius of 51.45, while the track size is about 343x343 with a stacking arrangement.\n"
     ]
    }
   ],
   "source": [
    "# specs = os.listdir(specs_dir)\n",
    "\n",
    "# for example in specs[0:1]:\n",
    "#     name_i = example.split(\".json\")[0]\n",
    "#     files = get_files(name_i)\n",
    "\n",
    "#     response = send_prompt(prompt, model, files)\n",
    "#     print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = os.listdir(specs_dir)\n",
    "\n",
    "for example in specs[0:10]:\n",
    "    name_i = example.split(\".json\")[0]\n",
    "    files = get_files(name_i)\n",
    "\n",
    "    response = send_prompt(prompt, model, files)\n",
    "    with open(os.path.join(alt_dir, \"altgosling-llm\", f\"{name_i}.txt\"), \"w\") as f:\n",
    "        f.write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EX_SPEC_CIRCULR_RANGE_sw_0_7_s_0_7_cc_0.json',\n",
       " 'EX_SPEC_GREMLIN_sw_1_2_s_0_7_cc_1.json',\n",
       " 'gray_heatmap_sw_1_0_s_1_0_oc_sw_0_7_s_1_0_cc_0.json',\n",
       " 'TEXT_sw_0_7_s_1_0_cc_0.json',\n",
       " 'PBCA-DE-2009e5e7-1796-445b-8677-46b3804fe0bf.json',\n",
       " 'POINT_sw_1_2_s_1_2_cc_2.json',\n",
       " 'AREA_sw_1_2_s_1_2_oc.json',\n",
       " 'responsive-circular_p_0_sw_1_0_s_1_0_oc.json',\n",
       " 'combination-point-area_p_0_sw_1_2_s_0_7_cc_0.json',\n",
       " 'EX_SPEC_CIRCOS_sw_0_7_s_0_7_cc_2.json']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
