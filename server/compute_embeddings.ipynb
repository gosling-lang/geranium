{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e89213-91ea-4213-a2f1-a26f77343907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model, preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f\"Model loaded on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd8c11-fbb0-4fad-8d9c-a7ba61fa07aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input directories\n",
    "image_folder = \"../data/unified/imgs\"\n",
    "text_folder = \"../data/unified/alt\"\n",
    "spec_folder = \"../data/unified/specs\"\n",
    "output_folder = \"./embeddings\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "batch_size = 50  # Adjust batch size as needed\n",
    "context_length = 256\n",
    "\n",
    "def generate_text_embeddings(folder, output_name, alt_version = None):\n",
    "    if alt_version:\n",
    "        folder = f\"{folder}_{alt_version}\"\n",
    "    text_files = [f for f in os.listdir(folder) if f.lower().endswith(\".txt\") or f.lower().endswith(\".json\")]\n",
    "    text_embeddings = []\n",
    "    file_names = []\n",
    "    \n",
    "    for i in range(0, len(text_files), batch_size):\n",
    "        batch_files = text_files[i:i + batch_size]\n",
    "        texts = []\n",
    "        \n",
    "        for text_file in batch_files:\n",
    "            text_path = os.path.join(folder, text_file)\n",
    "            \n",
    "            with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                if text_file.lower().endswith(\".json\"):\n",
    "                    try:\n",
    "                        data = json.load(f)\n",
    "                        text_desc = json.dumps(data)  # Convert JSON object to a string\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Warning: Could not parse JSON in {text_file}, skipping.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    text_desc = f.read().strip()\n",
    "            \n",
    "            texts.append(text_desc)\n",
    "            file_names.append(text_file)\n",
    "        \n",
    "        text_input = tokenizer(texts, context_length=context_length).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            text_features = model.encode_text(text_input)\n",
    "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        text_embeddings.append(text_features.cpu().numpy())\n",
    "        print(f\"Processed {i + batch_size} of {len(text_files)} text files.\")\n",
    "    \n",
    "    save_embeddings(text_embeddings, file_names, output_name)\n",
    "\n",
    "# Function to generate image embeddings in batches\n",
    "def generate_image_embeddings(folder, output_name):\n",
    "    image_files = [f for f in os.listdir(folder) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "    image_embeddings = []\n",
    "    file_names = []\n",
    "    \n",
    "    for i in range(0, len(image_files), batch_size):\n",
    "        batch_files = image_files[i:i + batch_size]\n",
    "        images = []\n",
    "        \n",
    "        for image_file in batch_files:\n",
    "            image_path = os.path.join(folder, image_file)\n",
    "            image = preprocess(Image.open(image_path).convert(\"RGB\"))\n",
    "            images.append(image)\n",
    "            file_names.append(image_file)\n",
    "        \n",
    "        images_tensor = torch.stack(images).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(images_tensor)\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        image_embeddings.append(image_features.cpu().numpy())\n",
    "        print(f\"Processed {i + batch_size} of {len(image_files)} image files.\")\n",
    "    \n",
    "    save_embeddings(image_embeddings, file_names, output_name)\n",
    "\n",
    "# Function to save embeddings as TSV and Parquet\n",
    "def save_embeddings(embeddings, file_names, output_name):\n",
    "    if not embeddings:\n",
    "        print(f\"No embeddings generated for {output_name}\")\n",
    "        return\n",
    "    \n",
    "    embeddings_np = np.vstack(embeddings)\n",
    "    df = pd.DataFrame(embeddings_np, columns=[f\"dim_{i}\" for i in range(embeddings_np.shape[1])])\n",
    "    df.insert(0, \"file_name\", file_names)\n",
    "    \n",
    "    tsv_path = os.path.join(output_folder, f\"{output_name}.tsv\")\n",
    "    parquet_path = os.path.join(output_folder, f\"{output_name}.parquet\")\n",
    "    \n",
    "    df.to_csv(tsv_path, sep=\"\\t\", index=False)\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "    \n",
    "    print(f\"Embeddings saved: {tsv_path} and {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89a685-42b6-42d4-a431-c7d790af5f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "print(\"Generating text embeddings...\")\n",
    "generate_text_embeddings(text_folder, \"text_embeddings\", alt_version=\"0_2_2\")\n",
    "\n",
    "print(\"Generating specification embeddings...\")\n",
    "generate_text_embeddings(spec_folder, \"spec_embeddings\")\n",
    "\n",
    "print(\"Generating image embeddings...\")\n",
    "generate_image_embeddings(image_folder, \"image_embeddings\")\n",
    "\n",
    "print(\"All embeddings generated and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eea80d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings 0_2_4\n",
    "print(\"Generating text embeddings...\")\n",
    "generate_text_embeddings(text_folder, \"text_0_2_4_embeddings\", alt_version=\"0_2_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa764fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings 0_2_4_llm_fs_single\n",
    "print(\"Generating text embeddings...\")\n",
    "generate_text_embeddings(text_folder, \"text_0_2_4_llm_fs_single_embeddings\", alt_version=\"0_2_4_llm_fs_single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc4c2f-0fc8-419c-8e9f-e54ea2dd9907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the TSV file\n",
    "tsv_path = \"./embeddings/image_embeddings.tsv\"\n",
    "df_tsv = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(df_tsv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb542b85-585d-4ff3-b958-a64005319888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Parquet file\n",
    "parquet_path = \"./embeddings/spec_frequency.parquet\"\n",
    "df_parquet = pd.read_parquet(parquet_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df_parquet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4db0f2-483c-4983-8693-f512b8eb5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TSV to parquet\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "tsv_path = \"./embeddings/spec_frequency.tsv\"\n",
    "parquet_path = \"./embeddings/spec_onehot.parquet\"\n",
    "\n",
    "# Read the TSV file\n",
    "df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "# Save as Parquet file\n",
    "df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "print(f\"Converted {tsv_path} to {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d641496-ab01-4757-b7c4-507c718fc534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
